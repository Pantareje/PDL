\documentclass{article}

% Soporte para Unicode.
% En vez de usar pdflatex, usa el comando xelatex.

\usepackage{fontspec}
\setmainfont{Latin Modern Roman}
\setmonofont{JetBrains Mono}

\usepackage[spanish]{babel} % Configuración para español
\usepackage[margin=1in]{geometry} % márgenes de la página
\usepackage{enumitem} % para listas personalizadas
\usepackage{fancyhdr} % para encabezados y pies de página
\usepackage[table]{xcolor} % para colores en tablas
\usepackage{xcolor} % para colores personalizados
\usepackage{hyperref} % para enlaces
\usepackage{tikz} % para dibujar diagramas (AFD)
\usepackage[most]{tcolorbox} % para cajas de texto
\usepackage{indentfirst} % para la sangría al iniciar una sección
\usepackage{listings} % para los códigos del anexo

\setlength{\headheight}{13.07225pt}
\addtolength{\topmargin}{-1.07225pt}

\pagestyle{fancy}
\fancyhead[L]{Grupo 7}
\fancyhead[C]{}
\fancyfoot[L]{Práctica 2 - Procesadores de Lenguajes}
\fancyfoot[C]{}
\fancyfoot[R]{\thepage}

\title{\textbf{Práctica 2 - Procesadores de Lenguajes}}
\author{\textbf{Grupo 7}\\Carmen Toribio Pérez, 22M009\\Sergio Gil Atienza, 22M046\\María Moronta Carrión, 22M111}
\date{}

\begin{document}

\maketitle

\tableofcontents

\section*{Introducción}

El proyecto a continuación consiste en la construcción de un procesador diseñado para analizar y verificar la corrección léxica, sintáctica y semántica del lenguaje JS--.

El trabajo comenzó con el análisis del lenguaje fuente para reconocer sus elementos fundamentales, lo que nos permitió identificar sus tokens. Gracias a ello, pudimos crear la gramática del lenguaje y su Autómata Finito Determinista equivalente. Con todo esto logramos implementar el Analizador Léxico, así como crear un diseño inicial de la Tabla de Símbolos, un núcleo fundamental para la organización de la información durante el análisis. 

A continuación, desarrollamos un Analizador Sintáctico, gracias a la identificación de una nueva gramática que nos permitió corregir la estructura del lenguaje. Finalmente, a esta gramática se integraron las Acciones Semánticas, permitiéndonos realizar la Traducción Dirigida por la Sintaxis propia del Analizador Semántico. 

Todo esto fue complementado por un Gestor de Errores claro y conciso, que mejora la experiencia de usuario a la hora de encontrar fallos localizados. El resultado final es un procesador capaz de interpretar un programa escrito en JS--. Esto queda demostrado en los distintos casos de prueba que incluimos. 

Como integrantes del \textbf{grupo 7}, hemos tenido que cumplir con las siguientes especificaciones: 
\begin{itemize}[left=2cm]
    \item Sentencias: Sentencia repetitiva (for)
    \item Operadores especiales: Asignación con suma (+=)
    \item Técnicas de Análisis Sintáctico: Descendente Recursivo
    \item Comentarios: Comentario de bloque (/* */)
    \item Cadenas: Con comillas simples (' ')
\end{itemize}

Además, hemos decidido usar \textbf{C++ como lenguaje de programación} ya que la mayor parte de la infraestructura de compiladores está escrita en C o en C++, incluyendo MSVC (desarrollado por Microsoft) y el proyecto LLVM (utilizado por Google en Android). También hemos tenido en cuenta su flexibilidad y potencia, junto a la amplia variedad de utilidades que tiene su librería estándar. En comparación con lenguajes como Java o JavaScript, C++ ofrece mayor eficiencia y control sobre los recursos del sistema, a la vez que se mantiene versátil y permite escribir código legible.

\newpage

\section{Analizador Léxico}
El \textbf{Analizador Léxico} constituye la primera etapa en el procesamiento de un lenguaje, pues es el encargado de interactuar directamente con el fichero fuente. Su propósito principal es identificar y clasificar las unidades mínimas del lenguaje, conocidas como \textbf{tokens}. Por ello, el primer paso es su identificación.

\subsection{Tokens}
Para hacer la lista de tokens nos hemos basado en la actividad práctica de la plataforma Draco. Hemos decidido utilizar el mismo formato en tablas con tal de facilitar su legibilidad.\\

{\small
\input{1.1.Tokens}}

Por tanto, los siguientes tipos de expresiones no serán identificados como tokens: los delimitadores (como los espacios en blanco o las tabulaciones), los comentarios de bloque (/* */) o los saltos de línea (\textbackslash n).

\subsection{Gramática Regular del Analizador Léxico}

En esta sección, describimos la Gramática Regular (gramática de tipo 3 según la jerarquía de Chomsky) que hemos diseñado para identificar y generar los tokens del lenguaje fuente. 

\input{1.2.GramaticaLex}

\subsection{Autómata Finito Determinista}
Una vez definida la gramática regular, el siguiente paso es construir el Autómata Finito Determinista (AFD) correspondiente. A continuación, presentamos su diseño, incluyendo las transiciones entre estados.

\input{1.3.AFD.tex}

\subsection{Acciones semánticas}
A lo largo de esta sección, describimos las acciones semánticas que hemos añadido a las transiciones del Autómata Finito Determinista. Estas acciones permiten que se lleven a cabo acciones como la lectura, la identificación de los tokens o, en su lugar, una correcta gestión de los errores léxicos. A continuación, detallamos las operaciones utilizadas y, por legibilidad en el AFD, las transiciones en las que se realiza cada una:\\
\input{1.4.AccSemanticas.tex}

\subsection{Gestión de errores}
\input{1.5.Errores.tex}

Para ilustrar mejor el comportamiento del programa, en la sección 8 presentamos varios casos en los que demostramos cómo el analizador maneja la detección de errores.

\section{Analizador Sintáctico}
El \textbf{Analizador Sintáctico} es la segunda etapa del proceso de análisis y tiene como objetivo principal verificar si la secuencia de tokens generada por el Analizador Léxico cumple con las reglas de la gramática del lenguaje. Su función es comprobar que la estructura del código fuente es válida, de acuerdo con la sintaxis definida para el lenguaje en cuestión. Por ello, recibe los tokens producidos por el Analizador Léxico y construye un árbol sintáctico, que representa la jerarquía y la organización de los elementos del programa. Para llevar a cabo esta tarea utiliza las reglas de una Gramática de Contexto Libre.

\subsection{Gramática de Contexto Libre del Analizador Sintáctico}

En esta sección, describimos la Gramática de Contexto Libre (gramática de tipo 2 según la jerarquía de Chomsky) que hemos diseñado para representar la estructura sintáctica del lenguaje fuente.

\input{2.1.GramaticaSin}

\subsection{Comprobación de la condición LL(1)}

\input{2.2.CondLL1}

\subsection{Pseudo-código con funciones del Analizador Sintáctico}

\input{2.3.Pseudocode}

\section{Analizador Semántico}
El \textbf{Analizador Semántico} es la tercera etapa del procesamiento de un lenguaje, cuyo objetivo es asegurar que el programa cumpla con las reglas y las expectativas semánticas del lenguaje. Una vez que el código ha sido analizado léxica y sintácticamente, el Analizador Semántico se encarga de verificar que las operaciones y relaciones entre los elementos del programa sean lógicas y coherentes. 

\subsection{Traducción Dirigida por la Sintaxis}
Para realizar este análisis semántico se debe llevar a cabo la \textbf{Traducción Dirigida por la Sintaxis}. La hemos representado mediante un \textbf{Esquema de Traducción}, para lo que se deben añadir las \textbf{Acciones Semánticas} directamente a la gramática del Analizador Sintáctico. 

\input{3.1.TDS}

\section{Tabla de Símbolos}
La Tabla de Símbolos (TS) es una estructura de datos fundamental en la implementación de un compilador o procesador de lenguajes. Su principal objetivo es \textbf{almacenar información sobre los identificadores} (variables, funciones, etc.) que aparecen en el programa fuente y organizarla de manera eficiente para su consulta durante las fases de análisis semántico y de ejecución. En nuestro caso, hemos implementado una TS lineal y dinámica, que gestiona tanto la información de los identificadores como los alcances de los mismos.

\subsection{Descripción de su estructura}
\input{4.1.EstructuraTS}

\subsection{Organización}
\input{4.2.OrganizTS}

\subsection{Ejemplo de organización de la Tabla de Símbolos}
\input{4.3.EjemploTS}

\section{Diseño del Gestor de Errores}

El gestor de errores permite identificar y manejar los problemas encontrados durante las fases de análisis léxico, sintáctico y semántico. Este diseño asegura que el compilador pueda ofrecer mensajes claros y detallados al usuario, mejorando la experiencia de depuración. El gestor de errores de nuestro procesador está diseñado para manejar los siguientes aspectos:

\begin{itemize}
    \item \textbf{Manejo de mensajes de error:} Cada error tiene un código único y un mensaje descriptivo que facilita su identificación y comprensión. Los mensajes están diseñados para proporcionar contexto sobre la causa del error, incluyendo información sobre el símbolo, línea y columna involucrados.
    \item \textbf{Distinción entre tipos de error:} Los errores se clasifican en léxicos, sintácticos y semánticos, cada uno con un conjunto específico de códigos y mensajes, explicados en los puntos a continuación.
    \item \textbf{Gestión del número de línea y columna:} El gestor de errores mantiene un registro del número de línea y columna mientras procesa el código fuente. Concretamente, las clases Excepción incluyen los métodos GetLine y GetColumn. Esto permite informar sobre los errores junto a su ubicación exacta en el código, lo que facilita su corrección. 
    \item \textbf{Modos de recuperación en errores léxicos y semánticos:} El sistema puede configurarse para actuar de distintas maneras ante errores: continuar procesando al omitir un carácter, una línea completa o detenerse inmediatamente si el error es crítico. Sin embargo, no hemos implementado esta opción con los errores sintácticos al ser sus errores mucho más complejos, pues pueden afectar a muchas partes del código.
\end{itemize}

\subsection*{Lista de Códigos de Error}

\input{5.1.ErroresLex}

\input{5.2.ErroresSin}

\input{5.3.ErroresSem}


\section{Demostración del funcionamiento}
El programa realizado toma como entrada los tokens generados por el Analizador Léxico y los organiza siguiendo las reglas gramaticales que hemos definido previamente. Este proceso verifica que el código fuente cumple con la estructura sintáctica esperada, generando un fichero de parse o detectando errores. Gracias a la herramienta VASt y la gramática es posible visualizar los árboles sintácticos.

En el \textbf{Anexo A} es posible encontrar múltiples ejemplos que demuestran el funcionamiento correcto del programa. A continuación incluimos una breve explicación de cada uno:

\begin{itemize}
    \item \textbf{Caso 1:} Con este caso demostramos el correcto funcionamiento de la declaración de funciones y de variables (tanto globales como locales). Además, puede apreciarse cómo estructuras como el bucle for o 'output' funcionan adecuadamente.

    \item \textbf{Caso 2:} En este ejemplo mostramos cómo pasar como parámetro una variable sin inicializar se trata de un error detectado en tiempo de ejecución o un comportamiento indefinido, así que no nos afecta.
    
    \item \textbf{Caso 3:} Este caso demuestra cómo el programa respeta el orden de prioridad de las operaciones.
    
    \item \textbf{Caso 4:} Con este ejemplo queda constancia de cómo la estructura for funciona apropiadamente (incluso con una sentencia vacía en la inicialización). También mostramos la correcta implementación de la estructura if, y la posibilidad de existir varios valores de retorno en una función.
    
    \item \textbf{Caso 5:} Finalmente, ilustramos cómo los operadores '+' y '+=' concatenan adecuadamente cadenas. También queda probado con este último ejemplo el correcto funcionamiento de la declaración implícita de variables.
\end{itemize}

En el \textbf{Anexo B} pueden verse otra serie de ejemplos que muestran el proceder del programa ante distintos tipos de errores. A continuación incluimos una breve explicación de cada uno:

\begin{itemize}
    \item \textbf{Caso 6:} Con este caso demostramos cómo se producen errores semánticos si tratamos de declarar de nuevo una variable con el mismo nombre o si tenemos un valor de retorno incorrecto en una función. Además, finalmente se produce un error sintáctico y crítico debido a la falta del tipo de retorno de una función.

    \item \textbf{Caso 7:} En este ejemplo, hay múltiples errores semánticos. Finalmente, muestra cómo el analizador detecta un error léxico al intentar escribir un comentario sin cerrarlo.
    
    \item \textbf{Caso 8:} Demostramos con este caso cómo al declarar una variable implícitamente, su tipo se vuelve entero. Esto hace que surja un error semántico si tratamos de igualarla a otro tipo de dato, pues sucede un conflicto de tipos. Finalmente, surgirá otro error sintáctico crítico al intentar utilizar la palabra 'bulean' como un tipo de variable. De este modo, lo termina considerando un identificador y al faltar su tipo, genera el error.

    \item \textbf{Caso 9:} Ilustramos cómo operaciones entre tipos disjuntos producen un error semántico.
    
    \item \textbf{Caso 10:} Mostramos de nuevo cómo si intentamos sumar un valor lógico a una variable entera, se produce un error semántico. En caso de que un entero exceda el límite permitido, también se producirá un error léxico. Y, finalmente, la aparición de caracteres no imprimibles en una cadena (como un salto de línea) también provoca un error léxico.
\end{itemize}

Con esto demostramos el funcionamiento del Procesador por completo, poniendo en manifiesto su capacidad de procesar correctamente código y de identificar errores con mensajes claros y precisos. 

\newpage
\input{Anexo.tex}
\newpage

\end{document}